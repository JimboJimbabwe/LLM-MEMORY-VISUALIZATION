Do you ever wonder what would happen if we gave an Orangutan the ability to translate its thoughts?

Me neither, however - the ability to transform a high degree of sapien nonsense into coherent output is a marvel to watch.

How could we bolster the efficacy of something that does this?

A good place to start, according to the LLM Community - would be with a RAG.

Local Memory: As if 80 Gorillion Tokens of Training Data wasn't enough.

![BaseConcepts1 drawio](https://github.com/JimboJimbabwe/LLM-MEMORY-VISUALIZATION/assets/32883805/7ff6b5ed-0b94-41de-a036-c5984ec771b2)

Your AI can be augmented (improved) by giving it a Memory to Retrieve from to Generate an output. RAG = Retrieval Augmented Generation (More or Less)

What can make it better?

Self-Reflecting Functionality:

![SELFREFECTBaseConcepts2 drawio](https://github.com/JimboJimbabwe/LLM-MEMORY-VISUALIZATION/assets/32883805/8de1ad23-e144-4ec5-9979-4f1194bd6174)


Have you ever sat on a thought a couple times before it came out of your mouth? Think of the above image as a ML Equivalent of thinking before you speak.

Self-Reflecting Artifical Intelligence can be good when applied in a manner that requires specialized output tuning achieved from LLM Environment tuning. 
(Whatever you call the Temperature and token settings man, cut me some slack)

What's better than ONE AI that can think before it speaks? TWO AI's that can think before they speak!

 ![AIMemoryChart1](https://github.com/JimboJimbabwe/LLM-MEMORY-VISUALIZATION/assets/32883805/1a486efb-d3eb-4c1c-8cd9-c26a2a9f4fab)

Diversity of Opinion is crucial, but can't any lost-soul hotwire a Python script to get two opinions from two separate LLM's?

Absolutely, that is why you give it a friend:

![AIMEMORY2 drawio](https://github.com/JimboJimbabwe/LLM-MEMORY-VISUALIZATION/assets/32883805/99f00472-3446-477e-8e3a-4ea461bfe5ee)

Each AI has their own Context Data to help them complete a given directive, when you feed their own output back into their input, and share other output of other AI responding to the directive - I believe you can achieve a better filter.

Among many other things - see my Repo: AI CONGRESS. 

The progression of these LLM's in the manner that they are, might simply imply I am observing something already defined. However, the ability to bolster the efficacy of transforming any human-readable input into any coherent output is an open field of opportunity in my own opinion. Provided this above model is possible, it opens the door for much testing to be done.

![WebForBaseConcepts drawio](https://github.com/JimboJimbabwe/LLM-MEMORY-VISUALIZATION/assets/32883805/01f65d7c-f9bb-4fa5-8050-f37bbdc03700)

For now, that testing can wait. My GPU is begging for mercy.
